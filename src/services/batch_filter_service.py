"""
æ‰¹é‡ç­›é€‰æœåŠ¡ - ç®¡ç†å¤šä¸ªè®¢é˜…æºçš„è‡ªåŠ¨åˆ‡æ¢å’Œæ‰¹é‡ç­›é€‰
"""
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import List, Optional, Dict, Any, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed

from ..models.news import NewsArticle
from ..models.rss import RSSFeed, RSSArticle
from ..services.custom_rss_service import CustomRSSService
from ..services.filter_service import get_filter_service, FilterProgressCallback
from ..filters.base import (
    FilterChainResult,
    SubscriptionFilterResult,
    BatchFilterResult,
    CombinedFilterResult
)

logger = logging.getLogger(__name__)



class BatchFilterProgressCallback:
    """æ‰¹é‡ç­›é€‰è¿›åº¦å›è°ƒæ¥å£"""
    
    def on_batch_start(self, total_subscriptions: int):
        """æ‰¹é‡ç­›é€‰å¼€å§‹"""
        pass
    
    def on_subscription_start(self, subscription, current: int, total: int):
        """å¼€å§‹å¤„ç†è®¢é˜…æº"""
        pass
    
    def on_subscription_fetch_complete(self, subscription, articles_count: int):
        """è®¢é˜…æºæ–‡ç« è·å–å®Œæˆ"""
        pass
    
    def on_subscription_filter_complete(self, subscription, selected_count: int):
        """è®¢é˜…æºç­›é€‰å®Œæˆ"""
        pass
    
    def on_subscription_error(self, subscription, error: str):
        """è®¢é˜…æºå¤„ç†é”™è¯¯"""
        pass
    
    def on_batch_complete(self, result: BatchFilterResult):
        """æ‰¹é‡ç­›é€‰å®Œæˆ"""
        pass


class BatchFilterConfig:
    """æ‰¹é‡ç­›é€‰é…ç½®"""
    
    def __init__(self):
        # è®¢é˜…æºç­›é€‰é…ç½®
        self.max_subscriptions: Optional[int] = None  # æœ€å¤§å¤„ç†è®¢é˜…æºæ•°é‡
        self.subscription_filter: Optional[Callable[[any], bool]] = None  # è®¢é˜…æºè¿‡æ»¤å‡½æ•°

        # æ–‡ç« è·å–é…ç½®
        self.articles_per_subscription: int = 50  # æ¯ä¸ªè®¢é˜…æºè·å–çš„æ–‡ç« æ•°é‡
        self.exclude_read: bool = True  # æ˜¯å¦æ’é™¤å·²è¯»æ–‡ç« 
        self.hours_back: Optional[int] = 24  # è·å–å¤šå°‘å°æ—¶å†…çš„æ–‡ç« 

        # ç­›é€‰é…ç½®
        self.filter_type: str = "chain"  # ç­›é€‰ç±»å‹: keyword, ai, chain
        self.enable_parallel: bool = True  # æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
        self.max_workers: int = 3  # æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°

        # ç»“æœé…ç½®
        self.max_results_per_subscription: Optional[int] = None  # æ¯ä¸ªè®¢é˜…æºæœ€å¤§ç»“æœæ•°
        self.min_score_threshold: Optional[float] = None  # æœ€å°åˆ†æ•°é˜ˆå€¼
        self.max_total_articles: Optional[int] = None  # æ‰¹é‡ç­›é€‰æœ€å¤§æ–‡ç« æ•°é™åˆ¶
        self.sort_by: str = "final_score"  # æ’åºæ–¹å¼: final_score, published, subscription
        self.group_by_subscription: bool = True  # æ˜¯å¦æŒ‰è®¢é˜…æºåˆ†ç»„æ˜¾ç¤º

    def set_ai_filter_rules(self, min_score: int = 20, max_articles: int = 30):
        """
        è®¾ç½®AIç­›é€‰è§„åˆ™çš„ä¾¿æ·æ–¹æ³•

        Args:
            min_score: AIç­›é€‰æœ€ä½åˆ†æ•°é˜ˆå€¼ï¼ˆé»˜è®¤20åˆ†ï¼‰
            max_articles: æ‰¹é‡ç­›é€‰æœ€å¤§æ–‡ç« æ•°é™åˆ¶ï¼ˆé»˜è®¤30ç¯‡ï¼‰
        """
        self.max_total_articles = max_articles
        print(f"ğŸ¯ è®¾ç½®AIç­›é€‰è§„åˆ™: æœ€ä½åˆ†æ•° {min_score} åˆ†ï¼Œæœ€å¤§æ–‡ç« æ•° {max_articles} ç¯‡")

        # åŒæ—¶æ›´æ–°FilterServiceçš„AIé…ç½®
        try:
            get_filter_service().update_config("ai", min_score_threshold=min_score, batch_max_articles=max_articles)
            print(f"âœ… AIç­›é€‰é…ç½®å·²æ›´æ–°")
        except Exception as e:
            print(f"âš ï¸  æ›´æ–°AIç­›é€‰é…ç½®å¤±è´¥: {e}")




class CustomRSSBatchFilterManager:
    """è‡ªå®šä¹‰RSSæ‰¹é‡ç­›é€‰ç®¡ç†å™¨"""

    def __init__(self):
        self.custom_rss_service = CustomRSSService()
        self.filter_service = get_filter_service()

    def filter_subscriptions_batch(self,
                                 config: BatchFilterConfig,
                                 callback: Optional[BatchFilterProgressCallback] = None) -> BatchFilterResult:
        """
        æ‰¹é‡ç­›é€‰è‡ªå®šä¹‰RSSè®¢é˜…æº

        Args:
            config: æ‰¹é‡ç­›é€‰é…ç½®
            callback: è¿›åº¦å›è°ƒ

        Returns:
            æ‰¹é‡ç­›é€‰ç»“æœ
        """
        start_time = datetime.now()

        # è·å–è‡ªå®šä¹‰RSSè®¢é˜…æºåˆ—è¡¨
        rss_feeds = self._get_filtered_rss_feeds(config)

        if not rss_feeds:
            logger.warning("No RSS feeds found for filtering")
            return BatchFilterResult(
                total_subscriptions=0,
                processed_subscriptions=0,
                processing_start_time=start_time,
                processing_end_time=datetime.now()
            )

        logger.info(f"Starting batch filtering for {len(rss_feeds)} RSS feeds")

        # åˆ›å»ºæ‰¹é‡ç»“æœå¯¹è±¡
        batch_result = BatchFilterResult(
            total_subscriptions=len(rss_feeds),
            processed_subscriptions=0,
            processing_start_time=start_time
        )

        # é€šçŸ¥æ‰¹é‡ç­›é€‰å¼€å§‹
        if callback:
            callback.on_batch_start(len(rss_feeds))

        # å¤„ç†è®¢é˜…æº
        if config.enable_parallel:
            self._process_rss_feeds_parallel(rss_feeds, config, batch_result, callback)
        else:
            self._process_rss_feeds_sequential(rss_feeds, config, batch_result, callback)

        # å®Œæˆå¤„ç†
        batch_result.processing_end_time = datetime.now()

        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        self._calculate_batch_statistics(batch_result)

        # é€šçŸ¥æ‰¹é‡ç­›é€‰å®Œæˆ
        if callback:
            callback.on_batch_complete(batch_result)

        logger.info(f"Batch filtering completed: {batch_result.processed_subscriptions}/{batch_result.total_subscriptions} RSS feeds processed")

        return batch_result

    def _get_filtered_rss_feeds(self, config: BatchFilterConfig) -> List[RSSFeed]:
        """è·å–è¿‡æ»¤åçš„RSSè®¢é˜…æºåˆ—è¡¨"""
        try:
            all_feeds = self.custom_rss_service.get_active_subscriptions()

            # åº”ç”¨è®¢é˜…æºè¿‡æ»¤å™¨
            filtered_feeds = []

            for feed in all_feeds:
                # è‡ªå®šä¹‰è¿‡æ»¤å‡½æ•°
                if config.subscription_filter and not config.subscription_filter(feed):
                    continue

                # ç›´æ¥æ·»åŠ æ‰€æœ‰é€šè¿‡è‡ªå®šä¹‰è¿‡æ»¤å™¨çš„è®¢é˜…æº
                filtered_feeds.append(feed)

            # é™åˆ¶æ•°é‡
            if config.max_subscriptions:
                filtered_feeds = filtered_feeds[:config.max_subscriptions]

            logger.info(f"Filtered {len(filtered_feeds)} RSS feeds from {len(all_feeds)} total")
            return filtered_feeds

        except Exception as e:
            logger.error(f"Failed to get RSS feeds: {e}")
            return []



    def _process_rss_feeds_sequential(self,
                                    feeds: List[RSSFeed],
                                    config: BatchFilterConfig,
                                    batch_result: BatchFilterResult,
                                    callback: Optional[BatchFilterProgressCallback]):
        """é¡ºåºå¤„ç†RSSè®¢é˜…æº"""
        for i, feed in enumerate(feeds):
            try:
                # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°æ–‡ç« æ•°é‡é™åˆ¶
                if config.max_total_articles:
                    current_total = sum(r.filter_result.final_selected_count for r in batch_result.subscription_results)
                    if current_total >= config.max_total_articles:
                        print(f"ğŸ›‘ æ‰¹é‡ç­›é€‰æå‰é€€å‡º: å·²è¾¾åˆ°æ–‡ç« æ•°é‡é™åˆ¶ {config.max_total_articles} ç¯‡")
                        logger.info(f"Batch filtering stopped: reached max articles limit ({config.max_total_articles})")
                        batch_result.warnings.append(f"å·²è¾¾åˆ°æœ€å¤§æ–‡ç« æ•°é‡é™åˆ¶ {config.max_total_articles}ï¼Œæå‰é€€å‡ºç­›é€‰")
                        break

                if callback:
                    subscription = self._rss_feed_to_subscription(feed)
                    callback.on_subscription_start(subscription, i + 1, len(feeds))

                result = self._process_single_rss_feed(feed, config, callback)
                batch_result.subscription_results.append(result)
                batch_result.processed_subscriptions += 1

                # å¤„ç†å®Œæˆåå†æ¬¡æ£€æŸ¥æ–‡ç« æ•°é‡
                if config.max_total_articles:
                    current_total = sum(r.filter_result.final_selected_count for r in batch_result.subscription_results)
                    print(f"ğŸ“Š å½“å‰ç´¯è®¡ç­›é€‰æ–‡ç« æ•°: {current_total}/{config.max_total_articles}")
                    if current_total >= config.max_total_articles:
                        print(f"ğŸ›‘ æ‰¹é‡ç­›é€‰è¾¾åˆ°é™åˆ¶: ç´¯è®¡ç­›é€‰äº† {current_total} ç¯‡æ–‡ç« ")
                        logger.info(f"Batch filtering completed: reached max articles limit ({current_total} articles)")
                        break

            except Exception as e:
                logger.error(f"Error processing RSS feed {feed.title}: {e}")
                batch_result.errors.append(f"RSS feed {feed.title}: {e}")

    def _process_rss_feeds_parallel(self,
                                  feeds: List[RSSFeed],
                                  config: BatchFilterConfig,
                                  batch_result: BatchFilterResult,
                                  callback: Optional[BatchFilterProgressCallback]):
        """å¹¶è¡Œå¤„ç†RSSè®¢é˜…æº"""
        # å¦‚æœè®¾ç½®äº†æ–‡ç« æ•°é‡é™åˆ¶ï¼Œä½¿ç”¨é¡ºåºå¤„ç†ä»¥ä¾¿æ›´å¥½åœ°æ§åˆ¶
        if config.max_total_articles:
            print(f"âš ï¸  æ£€æµ‹åˆ°æ–‡ç« æ•°é‡é™åˆ¶ ({config.max_total_articles})ï¼Œåˆ‡æ¢åˆ°é¡ºåºå¤„ç†æ¨¡å¼")
            logger.info(f"Switching to sequential processing due to max articles limit: {config.max_total_articles}")
            self._process_rss_feeds_sequential(feeds, config, batch_result, callback)
            return

        with ThreadPoolExecutor(max_workers=config.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_feed = {
                executor.submit(self._process_single_rss_feed, feed, config, callback): feed
                for feed in feeds
            }

            # æ”¶é›†ç»“æœ
            for i, future in enumerate(as_completed(future_to_feed)):
                feed = future_to_feed[future]
                try:
                    if callback:
                        subscription = self._rss_feed_to_subscription(feed)
                        callback.on_subscription_start(subscription, i + 1, len(feeds))

                    result = future.result()
                    batch_result.subscription_results.append(result)
                    batch_result.processed_subscriptions += 1

                except Exception as e:
                    logger.error(f"Error processing RSS feed {feed.title}: {e}")
                    batch_result.errors.append(f"RSS feed {feed.title}: {e}")

    def _process_single_rss_feed(self,
                               feed: RSSFeed,
                               config: BatchFilterConfig,
                               callback: Optional[BatchFilterProgressCallback]) -> SubscriptionFilterResult:
        """å¤„ç†å•ä¸ªRSSè®¢é˜…æº"""
        logger.debug(f"Processing RSS feed: {feed.title}")

        # è·å–æ–‡ç« 
        fetch_start = time.time()
        articles = self._get_rss_feed_articles(feed, config)
        fetch_time = time.time() - fetch_start

        if callback:
            subscription = self._rss_feed_to_subscription(feed)
            callback.on_subscription_fetch_complete(subscription, len(articles))

        # ç­›é€‰æ–‡ç« 
        if articles:
            filter_result = self.filter_service.filter_articles(
                articles=articles,
                filter_type=config.filter_type
            )

            # åº”ç”¨ç»“æœè¿‡æ»¤
            self._apply_result_filters(filter_result, config)
        else:
            # åˆ›å»ºç©ºçš„ç­›é€‰ç»“æœ
            filter_result = FilterChainResult(
                total_articles=0,
                processing_start_time=datetime.now()
            )
            filter_result.processing_end_time = datetime.now()

        if callback:
            callback.on_subscription_filter_complete(feed, filter_result.final_selected_count)

        return SubscriptionFilterResult(
            subscription_id=feed.id,
            subscription_title=feed.title,
            filter_result=filter_result,
            articles_fetched=len(articles),
            fetch_time=fetch_time
        )

    def _get_rss_feed_articles(self, feed: RSSFeed, config: BatchFilterConfig) -> List[NewsArticle]:
        """è·å–RSSè®¢é˜…æºçš„æ–‡ç« """
        try:
            # ä»RSS feedä¸­è·å–æ–‡ç« 
            rss_articles = feed.articles

            # åº”ç”¨æ—¶é—´è¿‡æ»¤
            if config.hours_back:
                cutoff_time = datetime.now(timezone.utc) - timedelta(hours=config.hours_back)
                rss_articles = [
                    article for article in rss_articles
                    if article.published >= cutoff_time
                ]

            # åº”ç”¨å·²è¯»è¿‡æ»¤
            if config.exclude_read:
                rss_articles = [
                    article for article in rss_articles
                    if not article.is_read
                ]

            # é™åˆ¶æ•°é‡
            if config.articles_per_subscription:
                rss_articles = rss_articles[:config.articles_per_subscription]

            # è½¬æ¢ä¸ºNewsArticleå¯¹è±¡
            news_articles = []
            for rss_article in rss_articles:
                news_article = self._rss_article_to_news_article(rss_article, feed)
                news_articles.append(news_article)

            return news_articles

        except Exception as e:
            logger.error(f"Failed to get articles from RSS feed {feed.title}: {e}")
            return []

    def _rss_article_to_news_article(self, rss_article: RSSArticle, feed: RSSFeed) -> NewsArticle:
        """å°†RSSArticleè½¬æ¢ä¸ºNewsArticleå¯¹è±¡"""
        # éœ€è¦æ·»åŠ updatedå­—æ®µï¼Œå¦‚æœRSSæ–‡ç« æ²¡æœ‰updatedæ—¶é—´ï¼Œä½¿ç”¨publishedæ—¶é—´
        updated_time = getattr(rss_article, 'updated', None) or rss_article.published

        # å¤„ç†ä½œè€…ä¿¡æ¯
        author = None
        if rss_article.author:
            from ..models.news import NewsAuthor
            author = NewsAuthor(name=rss_article.author)

        return NewsArticle(
            id=rss_article.id,
            title=rss_article.title,
            summary=rss_article.summary,
            content=rss_article.content,
            url=rss_article.url,
            published=rss_article.published,
            updated=updated_time,
            author=author,
            categories=[],  # RSSæ–‡ç« é€šå¸¸æ²¡æœ‰åˆ†ç±»ä¿¡æ¯
            is_read=rss_article.is_read,
            is_starred=False,  # RSSæ–‡ç« é€šå¸¸æ²¡æœ‰æ˜Ÿæ ‡åŠŸèƒ½
            feed_id=feed.id,
            feed_title=feed.title
        )

    def _apply_result_filters(self, filter_result: FilterChainResult, config: BatchFilterConfig):
        """åº”ç”¨ç»“æœè¿‡æ»¤é…ç½®"""
        # åº”ç”¨æœ€å°åˆ†æ•°é˜ˆå€¼
        if config.min_score_threshold is not None:
            if hasattr(filter_result, 'final_results') and filter_result.final_results:
                filter_result.final_results = [
                    result for result in filter_result.final_results
                    if getattr(result, 'final_score', 0) >= config.min_score_threshold
                ]
                filter_result.final_selected_count = len(filter_result.final_results)

        # åº”ç”¨æ¯ä¸ªè®¢é˜…æºæœ€å¤§ç»“æœæ•°é™åˆ¶
        if config.max_results_per_subscription is not None:
            if hasattr(filter_result, 'final_results') and filter_result.final_results:
                # æŒ‰åˆ†æ•°æ’åºå¹¶å–å‰Nä¸ª
                if hasattr(filter_result.final_results[0], 'final_score'):
                    filter_result.final_results.sort(
                        key=lambda x: getattr(x, 'final_score', 0),
                        reverse=True
                    )
                filter_result.final_results = filter_result.final_results[:config.max_results_per_subscription]
                filter_result.final_selected_count = len(filter_result.final_results)

    def _rss_feed_to_subscription(self, feed: RSSFeed):
        """å°†RSS Feedè½¬æ¢ä¸ºè®¢é˜…æºå¯¹è±¡ï¼ˆç”¨äºå›è°ƒï¼‰"""
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„è®¢é˜…æºå¯¹è±¡ï¼ŒåŒ…å«å¿…è¦çš„ä¿¡æ¯
        class SimpleSubscription:
            def __init__(self, feed: RSSFeed):
                self.id = feed.id
                self.title = feed.title
                self.url = feed.url
                self.category = getattr(feed, 'category', 'é»˜è®¤')
                self.description = getattr(feed, 'description', '')

        return SimpleSubscription(feed)

    def _calculate_batch_statistics(self, batch_result: BatchFilterResult):
        """è®¡ç®—æ‰¹é‡ç­›é€‰ç»Ÿè®¡ä¿¡æ¯"""
        batch_result.total_articles_fetched = sum(
            result.articles_fetched for result in batch_result.subscription_results
        )
        batch_result.total_articles_selected = sum(
            result.filter_result.final_selected_count for result in batch_result.subscription_results
        )

        # total_processing_timeæ˜¯åªè¯»å±æ€§ï¼Œç”±processing_end_time - processing_start_timeè‡ªåŠ¨è®¡ç®—
        # ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®


# å…¨å±€æ‰¹é‡ç­›é€‰ç®¡ç†å™¨å®ä¾‹
custom_rss_batch_filter_manager = CustomRSSBatchFilterManager()
