"""
æ‰¹é‡ç­›é€‰æœåŠ¡ - ç®¡ç†å¤šä¸ªè®¢é˜…æºçš„è‡ªåŠ¨åˆ‡æ¢å’Œæ‰¹é‡ç­›é€‰
"""
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import List, Optional, Dict, Any, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed

from ..models.news import NewsArticle
from ..models.subscription import Subscription
from ..models.rss import RSSFeed, RSSArticle
from ..services.news_service import NewsService
from ..services.subscription_service import SubscriptionService
from ..services.custom_rss_service import CustomRSSService
from ..services.filter_service import FilterService, FilterProgressCallback
from ..filters.base import (
    FilterChainResult,
    SubscriptionFilterResult,
    BatchFilterResult,
    CombinedFilterResult
)

logger = logging.getLogger(__name__)



class BatchFilterProgressCallback:
    """æ‰¹é‡ç­›é€‰è¿›åº¦å›è°ƒæ¥å£"""
    
    def on_batch_start(self, total_subscriptions: int):
        """æ‰¹é‡ç­›é€‰å¼€å§‹"""
        pass
    
    def on_subscription_start(self, subscription: Subscription, current: int, total: int):
        """å¼€å§‹å¤„ç†è®¢é˜…æº"""
        pass
    
    def on_subscription_fetch_complete(self, subscription: Subscription, articles_count: int):
        """è®¢é˜…æºæ–‡ç« è·å–å®Œæˆ"""
        pass
    
    def on_subscription_filter_complete(self, subscription: Subscription, selected_count: int):
        """è®¢é˜…æºç­›é€‰å®Œæˆ"""
        pass
    
    def on_subscription_error(self, subscription: Subscription, error: str):
        """è®¢é˜…æºå¤„ç†é”™è¯¯"""
        pass
    
    def on_batch_complete(self, result: BatchFilterResult):
        """æ‰¹é‡ç­›é€‰å®Œæˆ"""
        pass


class BatchFilterConfig:
    """æ‰¹é‡ç­›é€‰é…ç½®"""
    
    def __init__(self):
        # è®¢é˜…æºç­›é€‰é…ç½®
        self.max_subscriptions: Optional[int] = None  # æœ€å¤§å¤„ç†è®¢é˜…æºæ•°é‡
        self.subscription_filter: Optional[Callable[[Subscription], bool]] = None  # è®¢é˜…æºè¿‡æ»¤å‡½æ•°

        # æ–‡ç« è·å–é…ç½®
        self.articles_per_subscription: int = 50  # æ¯ä¸ªè®¢é˜…æºè·å–çš„æ–‡ç« æ•°é‡
        self.exclude_read: bool = True  # æ˜¯å¦æ’é™¤å·²è¯»æ–‡ç« 
        self.hours_back: Optional[int] = 24  # è·å–å¤šå°‘å°æ—¶å†…çš„æ–‡ç« 

        # ç­›é€‰é…ç½®
        self.filter_type: str = "chain"  # ç­›é€‰ç±»å‹: keyword, ai, chain
        self.enable_parallel: bool = True  # æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
        self.max_workers: int = 3  # æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°

        # ç»“æœé…ç½®
        self.max_results_per_subscription: Optional[int] = None  # æ¯ä¸ªè®¢é˜…æºæœ€å¤§ç»“æœæ•°
        self.min_score_threshold: Optional[float] = None  # æœ€å°åˆ†æ•°é˜ˆå€¼
        self.sort_by: str = "final_score"  # æ’åºæ–¹å¼: final_score, published, subscription
        self.group_by_subscription: bool = True  # æ˜¯å¦æŒ‰è®¢é˜…æºåˆ†ç»„æ˜¾ç¤º


class BatchFilterManager:
    """æ‰¹é‡ç­›é€‰ç®¡ç†å™¨"""
    
    def __init__(self, auth=None):
        self.news_service = NewsService(auth)
        self.subscription_service = SubscriptionService(auth)
        self.filter_service = FilterService()
        
    def filter_subscriptions_batch(self, 
                                 config: BatchFilterConfig,
                                 callback: Optional[BatchFilterProgressCallback] = None) -> BatchFilterResult:
        """
        æ‰¹é‡ç­›é€‰å¤šä¸ªè®¢é˜…æº
        
        Args:
            config: æ‰¹é‡ç­›é€‰é…ç½®
            callback: è¿›åº¦å›è°ƒ
            
        Returns:
            æ‰¹é‡ç­›é€‰ç»“æœ
        """
        start_time = datetime.now()
        
        # è·å–è®¢é˜…æºåˆ—è¡¨
        subscriptions = self._get_filtered_subscriptions(config)
        
        if not subscriptions:
            logger.warning("No subscriptions found for filtering")
            return BatchFilterResult(
                total_subscriptions=0,
                processed_subscriptions=0,
                processing_start_time=start_time,
                processing_end_time=datetime.now()
            )
        
        logger.info(f"Starting batch filtering for {len(subscriptions)} subscriptions")
        
        # åˆ›å»ºæ‰¹é‡ç»“æœå¯¹è±¡
        batch_result = BatchFilterResult(
            total_subscriptions=len(subscriptions),
            processed_subscriptions=0,
            processing_start_time=start_time
        )
        
        # é€šçŸ¥å¼€å§‹æ‰¹é‡ç­›é€‰
        if callback:
            callback.on_batch_start(len(subscriptions))
        
        # æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ–¹å¼
        if config.enable_parallel and len(subscriptions) > 1:
            self._process_subscriptions_parallel(subscriptions, config, batch_result, callback)
        else:
            self._process_subscriptions_sequential(subscriptions, config, batch_result, callback)
        
        # å®Œæˆå¤„ç†
        batch_result.processing_end_time = datetime.now()
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        self._calculate_batch_statistics(batch_result)
        
        # é€šçŸ¥æ‰¹é‡ç­›é€‰å®Œæˆ
        if callback:
            callback.on_batch_complete(batch_result)
        
        logger.info(f"Batch filtering completed: {batch_result.processed_subscriptions}/{batch_result.total_subscriptions} subscriptions processed")
        
        return batch_result
    
    def _get_filtered_subscriptions(self, config: BatchFilterConfig) -> List[Subscription]:
        """è·å–è¿‡æ»¤åçš„è®¢é˜…æºåˆ—è¡¨"""
        try:
            all_subscriptions = self.subscription_service.get_all_subscriptions()

            # åº”ç”¨è®¢é˜…æºè¿‡æ»¤å™¨
            filtered_subscriptions = []

            for subscription in all_subscriptions:
                # è‡ªå®šä¹‰è¿‡æ»¤å‡½æ•°
                if config.subscription_filter and not config.subscription_filter(subscription):
                    continue

                # ç›´æ¥æ·»åŠ æ‰€æœ‰é€šè¿‡è‡ªå®šä¹‰è¿‡æ»¤å™¨çš„è®¢é˜…æº
                filtered_subscriptions.append(subscription)

            # é™åˆ¶æ•°é‡
            if config.max_subscriptions:
                filtered_subscriptions = filtered_subscriptions[:config.max_subscriptions]

            logger.info(f"Filtered {len(filtered_subscriptions)} subscriptions from {len(all_subscriptions)} total")
            return filtered_subscriptions

        except Exception as e:
            logger.error(f"Failed to get subscriptions: {e}")
            return []
    
    def _process_subscriptions_sequential(self, 
                                        subscriptions: List[Subscription],
                                        config: BatchFilterConfig,
                                        batch_result: BatchFilterResult,
                                        callback: Optional[BatchFilterProgressCallback]):
        """é¡ºåºå¤„ç†è®¢é˜…æº"""
        for i, subscription in enumerate(subscriptions):
            try:
                if callback:
                    callback.on_subscription_start(subscription, i + 1, len(subscriptions))
                
                sub_result = self._process_single_subscription(subscription, config, callback)
                batch_result.subscription_results.append(sub_result)
                batch_result.processed_subscriptions += 1
                
            except Exception as e:
                error_msg = f"Failed to process subscription {subscription.title}: {e}"
                logger.error(error_msg)
                batch_result.errors.append(error_msg)
                
                if callback:
                    callback.on_subscription_error(subscription, str(e))
    
    def _process_subscriptions_parallel(self, 
                                      subscriptions: List[Subscription],
                                      config: BatchFilterConfig,
                                      batch_result: BatchFilterResult,
                                      callback: Optional[BatchFilterProgressCallback]):
        """å¹¶è¡Œå¤„ç†è®¢é˜…æº"""
        with ThreadPoolExecutor(max_workers=config.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_subscription = {
                executor.submit(self._process_single_subscription, subscription, config, callback): subscription
                for subscription in subscriptions
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_subscription):
                subscription = future_to_subscription[future]
                try:
                    sub_result = future.result()
                    batch_result.subscription_results.append(sub_result)
                    batch_result.processed_subscriptions += 1
                    
                except Exception as e:
                    error_msg = f"Failed to process subscription {subscription.title}: {e}"
                    logger.error(error_msg)
                    batch_result.errors.append(error_msg)
                    
                    if callback:
                        callback.on_subscription_error(subscription, str(e))
    
    def _process_single_subscription(self, 
                                   subscription: Subscription,
                                   config: BatchFilterConfig,
                                   callback: Optional[BatchFilterProgressCallback]) -> SubscriptionFilterResult:
        """å¤„ç†å•ä¸ªè®¢é˜…æº"""
        logger.debug(f"Processing subscription: {subscription.title}")
        
        # è·å–æ–‡ç« 
        fetch_start = time.time()
        articles = self.news_service.get_articles_by_feed(
            feed_id=subscription.id,
            count=config.articles_per_subscription,
            exclude_read=config.exclude_read
        )
        fetch_time = time.time() - fetch_start
        
        if callback:
            callback.on_subscription_fetch_complete(subscription, len(articles))
        
        # ç­›é€‰æ–‡ç« 
        if articles:
            filter_result = self.filter_service.filter_articles(
                articles=articles,
                filter_type=config.filter_type
            )
            
            # åº”ç”¨ç»“æœè¿‡æ»¤
            self._apply_result_filters(filter_result, config)
        else:
            # åˆ›å»ºç©ºçš„ç­›é€‰ç»“æœ
            filter_result = FilterChainResult(
                total_articles=0,
                processing_start_time=datetime.now()
            )
            filter_result.processing_end_time = datetime.now()
        
        if callback:
            callback.on_subscription_filter_complete(subscription, filter_result.final_selected_count)
        
        return SubscriptionFilterResult(
            subscription_id=subscription.id,
            subscription_title=subscription.title,
            filter_result=filter_result,
            articles_fetched=len(articles),
            fetch_time=fetch_time
        )
    
    def _apply_result_filters(self, filter_result: FilterChainResult, config: BatchFilterConfig):
        """åº”ç”¨ç»“æœè¿‡æ»¤é…ç½®"""
        if not filter_result.selected_articles:
            return
        
        # åˆ†æ•°é˜ˆå€¼è¿‡æ»¤
        if config.min_score_threshold is not None:
            filter_result.selected_articles = [
                article for article in filter_result.selected_articles
                if article.final_score >= config.min_score_threshold
            ]
        
        # æ•°é‡é™åˆ¶
        if config.max_results_per_subscription is not None:
            # æŒ‰åˆ†æ•°æ’åºåå–å‰Nä¸ª
            filter_result.selected_articles.sort(key=lambda x: x.final_score, reverse=True)
            filter_result.selected_articles = filter_result.selected_articles[:config.max_results_per_subscription]
        
        # æ›´æ–°æœ€ç»ˆé€‰ä¸­æ•°é‡
        filter_result.final_selected_count = len(filter_result.selected_articles)
    
    def _calculate_batch_statistics(self, batch_result: BatchFilterResult):
        """è®¡ç®—æ‰¹é‡ç»Ÿè®¡ä¿¡æ¯"""
        batch_result.total_articles_fetched = sum(
            sub_result.articles_fetched for sub_result in batch_result.subscription_results
        )
        batch_result.total_articles_selected = sum(
            sub_result.selected_count for sub_result in batch_result.subscription_results
        )
        batch_result.total_fetch_time = sum(
            sub_result.fetch_time for sub_result in batch_result.subscription_results
        )
        batch_result.total_filter_time = sum(
            sub_result.filter_result.total_processing_time for sub_result in batch_result.subscription_results
        )


    def get_sorted_results(self,
                         batch_result: BatchFilterResult,
                         config: BatchFilterConfig) -> List[CombinedFilterResult]:
        """è·å–æ’åºåçš„æ‰€æœ‰ç»“æœ"""
        all_articles = batch_result.all_selected_articles

        # æ’åº
        if config.sort_by == "final_score":
            all_articles.sort(key=lambda x: x.final_score, reverse=True)
        elif config.sort_by == "published":
            all_articles.sort(key=lambda x: x.article.published, reverse=True)
        elif config.sort_by == "subscription":
            all_articles.sort(key=lambda x: x.article.feed_title or "")

        return all_articles

    def export_results_to_dict(self, batch_result: BatchFilterResult) -> Dict[str, Any]:
        """å°†æ‰¹é‡ç­›é€‰ç»“æœå¯¼å‡ºä¸ºå­—å…¸æ ¼å¼"""
        return {
            "summary": {
                "total_subscriptions": batch_result.total_subscriptions,
                "processed_subscriptions": batch_result.processed_subscriptions,
                "success_rate": batch_result.success_rate,
                "total_articles_fetched": batch_result.total_articles_fetched,
                "total_articles_selected": batch_result.total_articles_selected,
                "total_processing_time": batch_result.total_processing_time,
                "processing_start_time": batch_result.processing_start_time.isoformat(),
                "processing_end_time": batch_result.processing_end_time.isoformat() if batch_result.processing_end_time else None
            },
            "subscription_results": [
                {
                    "subscription_id": sub_result.subscription_id,
                    "subscription_title": sub_result.subscription_title,
                    "articles_fetched": sub_result.articles_fetched,
                    "articles_selected": sub_result.selected_count,
                    "fetch_time": sub_result.fetch_time,
                    "filter_time": sub_result.filter_result.total_processing_time,
                    "selected_articles": [
                        {
                            "id": article.article.id,
                            "title": article.article.title,
                            "summary": article.article.summary,
                            "url": article.article.url,
                            "published": article.article.published.isoformat(),
                            "feed_title": article.article.feed_title,
                            "final_score": article.final_score,
                            "keyword_score": article.keyword_result.relevance_score if article.keyword_result else None,
                            "ai_score": article.ai_result.evaluation.total_score if article.ai_result else None,
                            "reasoning": article.ai_result.evaluation.reasoning if article.ai_result else None
                        }
                        for article in sub_result.filter_result.selected_articles
                    ]
                }
                for sub_result in batch_result.subscription_results
            ],
            "errors": batch_result.errors,
            "warnings": batch_result.warnings
        }


class CLIBatchProgressCallback(BatchFilterProgressCallback):
    """å‘½ä»¤è¡Œæ‰¹é‡ç­›é€‰è¿›åº¦å›è°ƒ"""

    def __init__(self, show_progress: bool = True):
        self.show_progress = show_progress
        self.total_subscriptions = 0
        self.current_subscription = 0

    def on_batch_start(self, total_subscriptions: int):
        """æ‰¹é‡ç­›é€‰å¼€å§‹"""
        self.total_subscriptions = total_subscriptions
        if self.show_progress:
            print(f"ğŸš€ å¼€å§‹æ‰¹é‡ç­›é€‰ {total_subscriptions} ä¸ªè®¢é˜…æº...")

    def on_subscription_start(self, subscription: Subscription, current: int, total: int):
        """å¼€å§‹å¤„ç†è®¢é˜…æº"""
        self.current_subscription = current
        if self.show_progress:
            print(f"ğŸ“° [{current}/{total}] å¤„ç†è®¢é˜…æº: {subscription.get_display_title()}")

    def on_subscription_fetch_complete(self, subscription: Subscription, articles_count: int):
        """è®¢é˜…æºæ–‡ç« è·å–å®Œæˆ"""
        if self.show_progress:
            print(f"   ğŸ“¥ è·å–åˆ° {articles_count} ç¯‡æ–‡ç« ")

    def on_subscription_filter_complete(self, subscription: Subscription, selected_count: int):
        """è®¢é˜…æºç­›é€‰å®Œæˆ"""
        if self.show_progress:
            print(f"   âœ… ç­›é€‰å®Œæˆï¼Œé€‰ä¸­ {selected_count} ç¯‡æ–‡ç« ")

    def on_subscription_error(self, subscription: Subscription, error: str):
        """è®¢é˜…æºå¤„ç†é”™è¯¯"""
        print(f"   âŒ å¤„ç†å¤±è´¥: {error}")

    def on_batch_complete(self, result: BatchFilterResult):
        """æ‰¹é‡ç­›é€‰å®Œæˆ"""
        if self.show_progress:
            print(f"\nğŸ‰ æ‰¹é‡ç­›é€‰å®Œæˆ!")
            print(f"   å¤„ç†è®¢é˜…æº: {result.processed_subscriptions}/{result.total_subscriptions}")
            print(f"   è·å–æ–‡ç« : {result.total_articles_fetched} ç¯‡")
            print(f"   é€‰ä¸­æ–‡ç« : {result.total_articles_selected} ç¯‡")
            print(f"   æ€»è€—æ—¶: {result.total_processing_time:.2f} ç§’")

            if result.errors:
                print(f"   é”™è¯¯æ•°é‡: {len(result.errors)}")


class CustomRSSBatchFilterManager:
    """è‡ªå®šä¹‰RSSæ‰¹é‡ç­›é€‰ç®¡ç†å™¨"""

    def __init__(self):
        self.custom_rss_service = CustomRSSService()
        self.filter_service = FilterService()

    def filter_subscriptions_batch(self,
                                 config: BatchFilterConfig,
                                 callback: Optional[BatchFilterProgressCallback] = None) -> BatchFilterResult:
        """
        æ‰¹é‡ç­›é€‰è‡ªå®šä¹‰RSSè®¢é˜…æº

        Args:
            config: æ‰¹é‡ç­›é€‰é…ç½®
            callback: è¿›åº¦å›è°ƒ

        Returns:
            æ‰¹é‡ç­›é€‰ç»“æœ
        """
        start_time = datetime.now()

        # è·å–è‡ªå®šä¹‰RSSè®¢é˜…æºåˆ—è¡¨
        rss_feeds = self._get_filtered_rss_feeds(config)

        if not rss_feeds:
            logger.warning("No RSS feeds found for filtering")
            return BatchFilterResult(
                total_subscriptions=0,
                processed_subscriptions=0,
                processing_start_time=start_time,
                processing_end_time=datetime.now()
            )

        logger.info(f"Starting batch filtering for {len(rss_feeds)} RSS feeds")

        # åˆ›å»ºæ‰¹é‡ç»“æœå¯¹è±¡
        batch_result = BatchFilterResult(
            total_subscriptions=len(rss_feeds),
            processed_subscriptions=0,
            processing_start_time=start_time
        )

        # é€šçŸ¥æ‰¹é‡ç­›é€‰å¼€å§‹
        if callback:
            callback.on_batch_start(len(rss_feeds))

        # å¤„ç†è®¢é˜…æº
        if config.enable_parallel:
            self._process_rss_feeds_parallel(rss_feeds, config, batch_result, callback)
        else:
            self._process_rss_feeds_sequential(rss_feeds, config, batch_result, callback)

        # å®Œæˆå¤„ç†
        batch_result.processing_end_time = datetime.now()

        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        self._calculate_batch_statistics(batch_result)

        # é€šçŸ¥æ‰¹é‡ç­›é€‰å®Œæˆ
        if callback:
            callback.on_batch_complete(batch_result)

        logger.info(f"Batch filtering completed: {batch_result.processed_subscriptions}/{batch_result.total_subscriptions} RSS feeds processed")

        return batch_result

    def _get_filtered_rss_feeds(self, config: BatchFilterConfig) -> List[RSSFeed]:
        """è·å–è¿‡æ»¤åçš„RSSè®¢é˜…æºåˆ—è¡¨"""
        try:
            all_feeds = self.custom_rss_service.get_active_subscriptions()

            # åº”ç”¨è®¢é˜…æºè¿‡æ»¤å™¨
            filtered_feeds = []

            for feed in all_feeds:
                # è½¬æ¢ä¸ºSubscriptionå¯¹è±¡ä»¥ä¾¿ä½¿ç”¨ç°æœ‰çš„è¿‡æ»¤é€»è¾‘
                subscription = self._rss_feed_to_subscription(feed)

                # è‡ªå®šä¹‰è¿‡æ»¤å‡½æ•°
                if config.subscription_filter and not config.subscription_filter(subscription):
                    continue

                # ç›´æ¥æ·»åŠ æ‰€æœ‰é€šè¿‡è‡ªå®šä¹‰è¿‡æ»¤å™¨çš„è®¢é˜…æº
                filtered_feeds.append(feed)

            # é™åˆ¶æ•°é‡
            if config.max_subscriptions:
                filtered_feeds = filtered_feeds[:config.max_subscriptions]

            logger.info(f"Filtered {len(filtered_feeds)} RSS feeds from {len(all_feeds)} total")
            return filtered_feeds

        except Exception as e:
            logger.error(f"Failed to get RSS feeds: {e}")
            return []

    def _rss_feed_to_subscription(self, feed: RSSFeed) -> Subscription:
        """å°†RSSFeedè½¬æ¢ä¸ºSubscriptionå¯¹è±¡"""
        return Subscription(
            id=feed.id,
            title=feed.title,
            url=feed.url,
            html_url=feed.link or feed.url
        )

    def _process_rss_feeds_sequential(self,
                                    feeds: List[RSSFeed],
                                    config: BatchFilterConfig,
                                    batch_result: BatchFilterResult,
                                    callback: Optional[BatchFilterProgressCallback]):
        """é¡ºåºå¤„ç†RSSè®¢é˜…æº"""
        for i, feed in enumerate(feeds):
            try:
                if callback:
                    subscription = self._rss_feed_to_subscription(feed)
                    callback.on_subscription_start(subscription, i + 1, len(feeds))

                result = self._process_single_rss_feed(feed, config, callback)
                batch_result.subscription_results.append(result)
                batch_result.processed_subscriptions += 1

            except Exception as e:
                logger.error(f"Error processing RSS feed {feed.title}: {e}")
                batch_result.errors.append(f"RSS feed {feed.title}: {e}")

    def _process_rss_feeds_parallel(self,
                                  feeds: List[RSSFeed],
                                  config: BatchFilterConfig,
                                  batch_result: BatchFilterResult,
                                  callback: Optional[BatchFilterProgressCallback]):
        """å¹¶è¡Œå¤„ç†RSSè®¢é˜…æº"""
        with ThreadPoolExecutor(max_workers=config.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_feed = {
                executor.submit(self._process_single_rss_feed, feed, config, callback): feed
                for feed in feeds
            }

            # æ”¶é›†ç»“æœ
            for i, future in enumerate(as_completed(future_to_feed)):
                feed = future_to_feed[future]
                try:
                    if callback:
                        subscription = self._rss_feed_to_subscription(feed)
                        callback.on_subscription_start(subscription, i + 1, len(feeds))

                    result = future.result()
                    batch_result.subscription_results.append(result)
                    batch_result.processed_subscriptions += 1

                except Exception as e:
                    logger.error(f"Error processing RSS feed {feed.title}: {e}")
                    batch_result.errors.append(f"RSS feed {feed.title}: {e}")

    def _process_single_rss_feed(self,
                               feed: RSSFeed,
                               config: BatchFilterConfig,
                               callback: Optional[BatchFilterProgressCallback]) -> SubscriptionFilterResult:
        """å¤„ç†å•ä¸ªRSSè®¢é˜…æº"""
        logger.debug(f"Processing RSS feed: {feed.title}")

        # è·å–æ–‡ç« 
        fetch_start = time.time()
        articles = self._get_rss_feed_articles(feed, config)
        fetch_time = time.time() - fetch_start

        if callback:
            subscription = self._rss_feed_to_subscription(feed)
            callback.on_subscription_fetch_complete(subscription, len(articles))

        # ç­›é€‰æ–‡ç« 
        if articles:
            filter_result = self.filter_service.filter_articles(
                articles=articles,
                filter_type=config.filter_type
            )

            # åº”ç”¨ç»“æœè¿‡æ»¤
            self._apply_result_filters(filter_result, config)
        else:
            # åˆ›å»ºç©ºçš„ç­›é€‰ç»“æœ
            filter_result = FilterChainResult(
                total_articles=0,
                processing_start_time=datetime.now()
            )
            filter_result.processing_end_time = datetime.now()

        if callback:
            subscription = self._rss_feed_to_subscription(feed)
            callback.on_subscription_filter_complete(subscription, filter_result.final_selected_count)

        return SubscriptionFilterResult(
            subscription_id=feed.id,
            subscription_title=feed.title,
            filter_result=filter_result,
            articles_fetched=len(articles),
            fetch_time=fetch_time
        )

    def _get_rss_feed_articles(self, feed: RSSFeed, config: BatchFilterConfig) -> List[NewsArticle]:
        """è·å–RSSè®¢é˜…æºçš„æ–‡ç« """
        try:
            # ä»RSS feedä¸­è·å–æ–‡ç« 
            rss_articles = feed.articles

            # åº”ç”¨æ—¶é—´è¿‡æ»¤
            if config.hours_back:
                cutoff_time = datetime.now(timezone.utc) - timedelta(hours=config.hours_back)
                rss_articles = [
                    article for article in rss_articles
                    if article.published >= cutoff_time
                ]

            # åº”ç”¨å·²è¯»è¿‡æ»¤
            if config.exclude_read:
                rss_articles = [
                    article for article in rss_articles
                    if not article.is_read
                ]

            # é™åˆ¶æ•°é‡
            if config.articles_per_subscription:
                rss_articles = rss_articles[:config.articles_per_subscription]

            # è½¬æ¢ä¸ºNewsArticleå¯¹è±¡
            news_articles = []
            for rss_article in rss_articles:
                news_article = self._rss_article_to_news_article(rss_article, feed)
                news_articles.append(news_article)

            return news_articles

        except Exception as e:
            logger.error(f"Failed to get articles from RSS feed {feed.title}: {e}")
            return []

    def _rss_article_to_news_article(self, rss_article: RSSArticle, feed: RSSFeed) -> NewsArticle:
        """å°†RSSArticleè½¬æ¢ä¸ºNewsArticleå¯¹è±¡"""
        # éœ€è¦æ·»åŠ updatedå­—æ®µï¼Œå¦‚æœRSSæ–‡ç« æ²¡æœ‰updatedæ—¶é—´ï¼Œä½¿ç”¨publishedæ—¶é—´
        updated_time = getattr(rss_article, 'updated', None) or rss_article.published

        # å¤„ç†ä½œè€…ä¿¡æ¯
        author = None
        if rss_article.author:
            from ..models.news import NewsAuthor
            author = NewsAuthor(name=rss_article.author)

        return NewsArticle(
            id=rss_article.id,
            title=rss_article.title,
            summary=rss_article.summary,
            content=rss_article.content,
            url=rss_article.url,
            published=rss_article.published,
            updated=updated_time,
            author=author,
            categories=[],  # RSSæ–‡ç« é€šå¸¸æ²¡æœ‰åˆ†ç±»ä¿¡æ¯
            is_read=rss_article.is_read,
            is_starred=False,  # RSSæ–‡ç« é€šå¸¸æ²¡æœ‰æ˜Ÿæ ‡åŠŸèƒ½
            feed_id=feed.id,
            feed_title=feed.title
        )

    def _apply_result_filters(self, filter_result: FilterChainResult, config: BatchFilterConfig):
        """åº”ç”¨ç»“æœè¿‡æ»¤é…ç½®"""
        # åº”ç”¨æœ€å°åˆ†æ•°é˜ˆå€¼
        if config.min_score_threshold is not None:
            if hasattr(filter_result, 'final_results') and filter_result.final_results:
                filter_result.final_results = [
                    result for result in filter_result.final_results
                    if getattr(result, 'final_score', 0) >= config.min_score_threshold
                ]
                filter_result.final_selected_count = len(filter_result.final_results)

        # åº”ç”¨æ¯ä¸ªè®¢é˜…æºæœ€å¤§ç»“æœæ•°é™åˆ¶
        if config.max_results_per_subscription is not None:
            if hasattr(filter_result, 'final_results') and filter_result.final_results:
                # æŒ‰åˆ†æ•°æ’åºå¹¶å–å‰Nä¸ª
                if hasattr(filter_result.final_results[0], 'final_score'):
                    filter_result.final_results.sort(
                        key=lambda x: getattr(x, 'final_score', 0),
                        reverse=True
                    )
                filter_result.final_results = filter_result.final_results[:config.max_results_per_subscription]
                filter_result.final_selected_count = len(filter_result.final_results)

    def _calculate_batch_statistics(self, batch_result: BatchFilterResult):
        """è®¡ç®—æ‰¹é‡ç­›é€‰ç»Ÿè®¡ä¿¡æ¯"""
        batch_result.total_articles_fetched = sum(
            result.articles_fetched for result in batch_result.subscription_results
        )
        batch_result.total_articles_selected = sum(
            result.filter_result.final_selected_count for result in batch_result.subscription_results
        )

        # total_processing_timeæ˜¯åªè¯»å±æ€§ï¼Œç”±processing_end_time - processing_start_timeè‡ªåŠ¨è®¡ç®—
        # ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®


# å…¨å±€æ‰¹é‡ç­›é€‰ç®¡ç†å™¨å®ä¾‹
batch_filter_manager = BatchFilterManager()
custom_rss_batch_filter_manager = CustomRSSBatchFilterManager()
