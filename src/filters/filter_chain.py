"""
ç­›é€‰é“¾ç®¡ç†å™¨å®ç°
"""
import time
import logging
from datetime import datetime
from typing import List, Optional, Callable, Tuple, Dict, Any
from ..models.news import NewsArticle
from ..config.filter_config import FilterChainConfig
from .keyword_filter import KeywordFilter
from .ai_filter import AIFilter
from .base import (
    FilterChainResult, CombinedFilterResult,
    KeywordFilterResult, AIFilterResult, ArticleTag
)

logger = logging.getLogger(__name__)


class FilterProgressCallback:
    """ç­›é€‰è¿›åº¦å›è°ƒæ¥å£"""

    def on_start(self, total_articles: int):
        """ç­›é€‰å¼€å§‹"""
        pass

    def on_keyword_progress(self, processed: int, total: int):
        """å…³é”®è¯ç­›é€‰è¿›åº¦"""
        pass

    def on_keyword_complete(self, results_count: int):
        """å…³é”®è¯ç­›é€‰å®Œæˆ"""
        pass

    def on_ai_start(self, total_articles: int):
        """AIç­›é€‰å¼€å§‹"""
        pass

    def on_ai_article_start(self, article_title: str, current: int, total: int):
        """å¼€å§‹è¯„ä¼°å•ç¯‡æ–‡ç« """
        pass

    def on_ai_article_complete(self, article_title: str, evaluation_score: float, processing_time: float):
        """å•ç¯‡æ–‡ç« è¯„ä¼°å®Œæˆ"""
        pass

    def on_ai_batch_start(self, batch_size: int, batch_number: int, total_batches: int):
        """AIæ‰¹å¤„ç†å¼€å§‹"""
        pass

    def on_ai_batch_complete(self, batch_size: int, batch_number: int, total_batches: int, avg_score: float):
        """AIæ‰¹å¤„ç†å®Œæˆ"""
        pass

    def on_ai_progress(self, processed: int, total: int):
        """AIç­›é€‰è¿›åº¦"""
        pass

    def on_ai_ranking_start(self, total_results: int):
        """AIç»“æœæ’åºå¼€å§‹"""
        pass

    def on_ai_ranking_complete(self, selected_count: int, total_count: int):
        """AIç»“æœæ’åºå®Œæˆ"""
        pass

    def on_ai_complete(self, results_count: int):
        """AIç­›é€‰å®Œæˆ"""
        pass

    def on_ai_error(self, article_title: str, error: str):
        """AIè¯„ä¼°é”™è¯¯"""
        pass

    def on_ai_fallback(self, article_title: str, reason: str):
        """AIé™çº§å¤„ç†"""
        pass

    def on_complete(self, final_count: int):
        """ç­›é€‰å®Œæˆ"""
        pass

    def on_error(self, error: str):
        """ç­›é€‰é”™è¯¯"""
        pass


class FilterChain:
    """ç­›é€‰é“¾ç®¡ç†å™¨"""

    def __init__(self,
                 keyword_filter: KeywordFilter,
                 ai_filter: AIFilter,
                 config: FilterChainConfig):
        self.keyword_filter = keyword_filter
        self.ai_filter = ai_filter
        self.config = config

        # åˆå§‹åŒ–æ ‡ç­¾è®¡æ•°å™¨ã€ç”Ÿæˆå™¨å’Œå¹³è¡¡é€‰æ‹©å™¨
        self.tag_counter = None
        self.tag_generator = None
        self.balanced_selector = None

        # å®‰å…¨åœ°è®¿é—®tag_balanceé…ç½®
        tag_balance_config = config.tag_balance

        # å¦‚æœtag_balanceæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå¯¹è±¡è®¿é—®
        if isinstance(tag_balance_config, dict):
            enable_tag_limits = tag_balance_config.get('enable_tag_limits', False)
            enable_tag_generation = tag_balance_config.get('enable_tag_generation', False)
            enable_balanced_selection = tag_balance_config.get('enable_balanced_selection', False)
            tag_limits = tag_balance_config.get('tag_limits', {})
            min_tag_score = tag_balance_config.get('min_tag_score', 0.2)
            max_tags_per_article = tag_balance_config.get('max_tags_per_article', 5)
            primary_tag_threshold = tag_balance_config.get('primary_tag_threshold', 0.5)
            underrepresented_boost = tag_balance_config.get('underrepresented_boost', 1.5)
        else:
            # å¯¹è±¡è®¿é—®
            enable_tag_limits = getattr(tag_balance_config, 'enable_tag_limits', False)
            enable_tag_generation = getattr(tag_balance_config, 'enable_tag_generation', False)
            enable_balanced_selection = getattr(tag_balance_config, 'enable_balanced_selection', False)
            tag_limits = getattr(tag_balance_config, 'tag_limits', {})
            min_tag_score = getattr(tag_balance_config, 'min_tag_score', 0.2)
            max_tags_per_article = getattr(tag_balance_config, 'max_tags_per_article', 5)
            primary_tag_threshold = getattr(tag_balance_config, 'primary_tag_threshold', 0.5)
            underrepresented_boost = getattr(tag_balance_config, 'underrepresented_boost', 1.5)

        if enable_tag_limits:
            from .tag_counter import TagCounter
            self.tag_counter = TagCounter(tag_limits)

        if enable_tag_generation:
            from .tag_generator import TagGenerator
            self.tag_generator = TagGenerator(
                min_tag_score=min_tag_score,
                max_tags_per_article=max_tags_per_article,
                primary_tag_threshold=primary_tag_threshold
            )

        if enable_balanced_selection and self.tag_counter:
            from .balanced_selector import BalancedSelector, BalanceStrategy
            strategy = BalanceStrategy(
                underrepresented_boost=underrepresented_boost
            )
            self.balanced_selector = BalancedSelector(self.tag_counter, strategy)

        # åˆå§‹åŒ–æ ‡ç­¾åˆ†æå™¨
        if enable_tag_generation:
            from .tag_analyzer import TagAnalyzer
            self.tag_analyzer = TagAnalyzer(tag_limits)
        else:
            self.tag_analyzer = None
    
    def process(self, articles: List[NewsArticle], test_mode: bool = False) -> FilterChainResult:
        """æ‰§è¡Œå®Œæ•´çš„ç­›é€‰æµç¨‹"""
        start_time = datetime.now()
        result = FilterChainResult(
            total_articles=len(articles),
            processing_start_time=start_time
        )
        
        try:
            logger.info(f"Starting filter chain for {len(articles)} articles")
            
            # ç¬¬ä¸€æ­¥ï¼šå…³é”®è¯ç­›é€‰
            keyword_results = self._execute_keyword_filter(articles, result)
            logger.info(f"Keyword filter completed: {len(keyword_results)} articles passed")
            
            # ç¬¬äºŒæ­¥ï¼šAIç­›é€‰
            ai_results = []
            print(f"ğŸ” ç»¼åˆç­›é€‰æ£€æŸ¥: enable_ai_filter={self.config.enable_ai_filter}, keyword_results={len(keyword_results)}")
            if self.config.enable_ai_filter and keyword_results:
                print(f"ğŸ¤– å¼€å§‹æ‰§è¡ŒAIç­›é€‰: {len(keyword_results)} ç¯‡å…³é”®è¯ç­›é€‰ç»“æœ")
                ai_results = self._execute_ai_filter(keyword_results, result, test_mode)
                print(f"âœ… AIç­›é€‰å®Œæˆ: {len(ai_results)} ç¯‡æ–‡ç« é€šè¿‡")
                logger.info(f"AI filter completed: {len(ai_results)} articles passed")
            elif not self.config.enable_ai_filter:
                print("âš ï¸  AIç­›é€‰å·²ç¦ç”¨")
            elif not keyword_results:
                print("âš ï¸  å…³é”®è¯ç­›é€‰æ— ç»“æœï¼Œè·³è¿‡AIç­›é€‰")
            
            # ç¬¬ä¸‰æ­¥ï¼šç»“æœæ•´åˆ
            final_results = self._combine_results(keyword_results, ai_results)
            self._finalize_results(final_results, result)
            
            logger.info(f"Filter chain completed: {result.final_selected_count} articles selected")
            
        except Exception as e:
            result.errors.append(f"ç­›é€‰æµç¨‹å¼‚å¸¸: {str(e)}")
            logger.error(f"Filter chain error: {e}", exc_info=True)
        
        finally:
            result.processing_end_time = datetime.now()
            result.total_processing_time = (
                result.processing_end_time - start_time
            ).total_seconds()
        
        return result
    
    def process_with_callback(self, articles: List[NewsArticle], 
                            callback: FilterProgressCallback, test_mode: bool = False) -> FilterChainResult:
        """å¸¦è¿›åº¦å›è°ƒçš„ç­›é€‰æµç¨‹"""
        callback.on_start(len(articles))
        
        try:
            start_time = datetime.now()
            result = FilterChainResult(
                total_articles=len(articles),
                processing_start_time=start_time
            )
            
            # å…³é”®è¯ç­›é€‰
            keyword_results = []
            if self.config.enable_keyword_filter:
                keyword_results = self._execute_keyword_filter_with_callback(
                    articles, result, callback
                )
                callback.on_keyword_complete(len(keyword_results))
            
            # AIç­›é€‰
            ai_results = []
            if self.config.enable_ai_filter and keyword_results:
                ai_results = self._execute_ai_filter_with_callback(
                    keyword_results, result, callback, test_mode
                )
                callback.on_ai_complete(len(ai_results))
            
            # æ•´åˆç»“æœ
            final_results = self._combine_results(keyword_results, ai_results)
            self._finalize_results(final_results, result)
            
            result.processing_end_time = datetime.now()
            result.total_processing_time = (
                result.processing_end_time - start_time
            ).total_seconds()
            
            callback.on_complete(result.final_selected_count)
            return result
            
        except Exception as e:
            callback.on_error(str(e))
            raise
    
    def _execute_keyword_filter(self, articles: List[NewsArticle], 
                              result: FilterChainResult) -> List[KeywordFilterResult]:
        """æ‰§è¡Œå…³é”®è¯ç­›é€‰"""
        if not self.config.enable_keyword_filter:
            return []
        
        start_time = time.time()
        try:
            keyword_results = self.keyword_filter.filter(articles)
            
            # åº”ç”¨é˜ˆå€¼è¿‡æ»¤
            filtered_results = [
                r for r in keyword_results 
                if r.relevance_score >= self.config.keyword_threshold
            ]
            
            # é™åˆ¶ç»“æœæ•°é‡
            if len(filtered_results) > self.config.max_keyword_results:
                filtered_results = sorted(
                    filtered_results, 
                    key=lambda x: x.relevance_score, 
                    reverse=True
                )[:self.config.max_keyword_results]
            
            result.keyword_filtered_count = len(filtered_results)
            result.keyword_filter_time = time.time() - start_time
            
            return filtered_results
            
        except Exception as e:
            result.errors.append(f"å…³é”®è¯ç­›é€‰å¤±è´¥: {str(e)}")
            if self.config.fail_fast:
                raise
            return []
    
    def _execute_ai_filter(self, keyword_results: List[KeywordFilterResult],
                         result: FilterChainResult, test_mode: bool = False) -> List[AIFilterResult]:
        """æ‰§è¡ŒAIç­›é€‰"""
        start_time = time.time()
        try:
            # æå–æ–‡ç« 
            articles = [kr.article for kr in keyword_results]
            
            # é™åˆ¶AIå¤„ç†æ•°é‡
            if len(articles) > self.config.max_ai_requests:
                # æŒ‰å…³é”®è¯åˆ†æ•°æ’åºï¼Œå–å‰Nä¸ª
                sorted_results = sorted(
                    keyword_results,
                    key=lambda x: x.relevance_score,
                    reverse=True
                )
                articles = [r.article for r in sorted_results[:self.config.max_ai_requests]]
                result.warnings.append(
                    f"AIç­›é€‰æ•°é‡é™åˆ¶ï¼Œä»…å¤„ç†å‰{self.config.max_ai_requests}ç¯‡æ–‡ç« "
                )
            
            if test_mode:
                # æµ‹è¯•æ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹ŸAIç­›é€‰ç»“æœ
                print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹ŸAIç­›é€‰ç»“æœ")
                ai_results = self._generate_mock_ai_results(articles)
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šè°ƒç”¨çœŸå®AI API
                ai_results = self.ai_filter.filter(articles)

            # AIç­›é€‰å™¨å·²ç»æŒ‰è¯„åˆ†æ’åºå¹¶è¿”å›å‰Næ¡ç»“æœï¼Œæ— éœ€å†æ¬¡è¿‡æ»¤
            result.ai_filtered_count = len(ai_results)
            result.ai_filter_time = time.time() - start_time

            return ai_results
            
        except Exception as e:
            result.errors.append(f"AIç­›é€‰å¤±è´¥: {str(e)}")
            if self.config.fail_fast:
                raise
            return []
    
    def _execute_keyword_filter_with_callback(self, articles: List[NewsArticle],
                                            result: FilterChainResult,
                                            callback: FilterProgressCallback) -> List[KeywordFilterResult]:
        """å¸¦å›è°ƒçš„å…³é”®è¯ç­›é€‰"""
        keyword_results = []
        batch_size = self.config.batch_size
        
        for i in range(0, len(articles), batch_size):
            batch = articles[i:i + batch_size]
            batch_results = []
            
            for article in batch:
                single_result = self.keyword_filter.filter_single(article)
                if single_result and single_result.relevance_score >= self.config.keyword_threshold:
                    batch_results.append(single_result)
            
            keyword_results.extend(batch_results)
            callback.on_keyword_progress(min(i + batch_size, len(articles)), len(articles))
        
        # é™åˆ¶ç»“æœæ•°é‡
        if len(keyword_results) > self.config.max_keyword_results:
            keyword_results = sorted(
                keyword_results,
                key=lambda x: x.relevance_score,
                reverse=True
            )[:self.config.max_keyword_results]
        
        result.keyword_filtered_count = len(keyword_results)
        return keyword_results
    
    def _execute_ai_filter_with_callback(self, keyword_results: List[KeywordFilterResult],
                                       result: FilterChainResult,
                                       callback: FilterProgressCallback, test_mode: bool = False) -> List[AIFilterResult]:
        """å¸¦å›è°ƒçš„AIç­›é€‰"""
        articles = [kr.article for kr in keyword_results]
        
        # é™åˆ¶AIå¤„ç†æ•°é‡
        if len(articles) > self.config.max_ai_requests:
            sorted_results = sorted(
                keyword_results,
                key=lambda x: x.relevance_score,
                reverse=True
            )
            articles = [r.article for r in sorted_results[:self.config.max_ai_requests]]
        
        ai_results = []
        batch_size = 5  # AIç­›é€‰ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡

        # æ”¶é›†æ‰€æœ‰AIè¯„ä¼°ç»“æœ
        all_results = []
        if test_mode:
            # æµ‹è¯•æ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿç»“æœ
            print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹ŸAIç­›é€‰ç»“æœ")
            all_results = self._generate_mock_ai_results(articles)
            # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
            for i in range(0, len(articles), batch_size):
                callback.on_ai_progress(min(i + batch_size, len(articles)), len(articles))
        else:
            # æ­£å¸¸æ¨¡å¼ï¼šè°ƒç”¨çœŸå®AI API
            for i in range(0, len(articles), batch_size):
                batch = articles[i:i + batch_size]
                batch_results = []

                for article in batch:
                    single_result = self.ai_filter.filter_single(article)
                    if single_result:
                        batch_results.append(single_result)

                all_results.extend(batch_results)
                callback.on_ai_progress(min(i + batch_size, len(articles)), len(articles))

        # æŒ‰è¯„åˆ†æ’åºå¹¶å–å‰Næ¡
        all_results.sort(key=lambda x: x.evaluation.total_score, reverse=True)
        max_selected = getattr(self.ai_filter.config, 'max_selected', 3)
        ai_results = all_results[:max_selected]

        # é€šçŸ¥æ‰€æœ‰AIè¯„ä¼°ç»“æœï¼ˆç”¨äºæ›´æ–°ç•Œé¢æ˜¾ç¤ºï¼‰
        if callback and hasattr(callback, 'on_all_ai_results'):
            callback.on_all_ai_results(all_results)

        result.ai_filtered_count = len(ai_results)
        return ai_results

    def _combine_results(self, keyword_results: List[KeywordFilterResult],
                        ai_results: List[AIFilterResult]) -> List[CombinedFilterResult]:
        """æ•´åˆå…³é”®è¯å’ŒAIç­›é€‰ç»“æœ"""
        combined_results = []

        # åˆ›å»ºAIç»“æœçš„å¿«é€ŸæŸ¥æ‰¾å­—å…¸
        ai_results_dict = {
            self._get_article_id(r.article): r for r in ai_results
        }

        for keyword_result in keyword_results:
            article_id = self._get_article_id(keyword_result.article)
            ai_result = ai_results_dict.get(article_id)

            # è®¡ç®—æœ€ç»ˆåˆ†æ•°
            final_score = self._calculate_final_score(keyword_result, ai_result)

            # åˆ¤æ–­æ˜¯å¦é€‰ä¸­
            selected, rejection_reason = self._determine_selection(
                keyword_result, ai_result, final_score
            )

            # ç”Ÿæˆæˆ–å¢å¼ºæ ‡ç­¾
            tags = self._generate_combined_tags(keyword_result, ai_result)

            combined_result = CombinedFilterResult(
                article=keyword_result.article,
                keyword_result=keyword_result,
                ai_result=ai_result,
                final_score=final_score,
                selected=selected,
                rejection_reason=rejection_reason,
                tags=tags
            )

            combined_results.append(combined_result)

        # å¦‚æœå¯ç”¨äº†æ ‡ç­¾å¹³è¡¡ï¼Œåº”ç”¨å¹³è¡¡ç­›é€‰
        if self.config.tag_balance.enable_balanced_selection and self.tag_counter:
            combined_results = self._apply_balanced_selection(combined_results)

        return combined_results

    def _generate_mock_ai_results(self, articles: List[NewsArticle]) -> List[AIFilterResult]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„AIç­›é€‰ç»“æœï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰"""
        import random
        from ..models.ai_filter_result import AIFilterResult, AIEvaluation
        
        mock_results = []
        for i, article in enumerate(articles):
            # ç”Ÿæˆéšæœºè¯„åˆ†ï¼ˆ15-30åˆ†ï¼‰
            score = random.randint(15, 30)
            
            # åˆ›å»ºæ¨¡æ‹Ÿè¯„ä¼°ç»“æœ
            evaluation = AIEvaluation(
                relevance_score=random.randint(3, 10),
                importance_score=random.randint(3, 10), 
                quality_score=random.randint(3, 10),
                total_score=score,
                reasoning=f"æ¨¡æ‹ŸAIè¯„ä¼°ï¼šè¿™æ˜¯ä¸€ç¯‡å…³äº{article.title[:20]}çš„æ–‡ç« ï¼Œè¯„åˆ†ä¸º{score}åˆ†"
            )
            
            # åˆ›å»ºAIç­›é€‰ç»“æœ
            ai_result = AIFilterResult(
                article=article,
                evaluation=evaluation,
                processing_time=random.uniform(0.1, 0.5),  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                selected=score >= 20  # 20åˆ†ä»¥ä¸Šè¢«é€‰ä¸­
            )
            
            mock_results.append(ai_result)
        
        # æŒ‰è¯„åˆ†æ’åº
        mock_results.sort(key=lambda x: x.evaluation.total_score, reverse=True)
        
        # é™åˆ¶ç»“æœæ•°é‡
        max_selected = getattr(self.ai_filter.config, 'max_selected', 3)
        return mock_results[:max_selected]

    def _generate_combined_tags(self, keyword_result: KeywordFilterResult,
                               ai_result: Optional[AIFilterResult]) -> List:
        """ç”Ÿæˆç»¼åˆæ ‡ç­¾"""
        if not self.tag_generator:
            return keyword_result.tags if keyword_result.tags else []

        # ä»å…³é”®è¯ç»“æœè·å–æ ‡ç­¾
        tags = keyword_result.tags if keyword_result.tags else []

        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œä»å…³é”®è¯ç»“æœç”Ÿæˆ
        if not tags:
            tags = self.tag_generator.generate_tags_from_keyword_result(keyword_result)

        # ä½¿ç”¨AIç»“æœå¢å¼ºæ ‡ç­¾
        if ai_result:
            tags = self.tag_generator.enhance_tags_with_ai_result(tags, ai_result)

        return tags

    def _apply_balanced_selection(self, combined_results: List[CombinedFilterResult]) -> List[CombinedFilterResult]:
        """åº”ç”¨æ ‡ç­¾å¹³è¡¡ç­›é€‰"""
        if not self.balanced_selector:
            return combined_results

        # ä½¿ç”¨å¹³è¡¡é€‰æ‹©å™¨è¿›è¡Œç­›é€‰
        return self.balanced_selector.select_balanced_articles(
            combined_results,
            max_results=self.config.max_final_results
        )

    def _calculate_final_score(self, keyword_result: KeywordFilterResult,
                             ai_result: Optional[AIFilterResult]) -> float:
        """è®¡ç®—æœ€ç»ˆç»¼åˆåˆ†æ•°"""
        keyword_score = keyword_result.relevance_score

        if ai_result is None:
            # ä»…æœ‰å…³é”®è¯åˆ†æ•°
            return keyword_score

        # ç»¼åˆè¯„åˆ†ï¼šå…³é”®è¯åˆ†æ•° * 0.3 + AIåˆ†æ•° * 0.7
        ai_score = ai_result.evaluation.total_score / 30.0  # å½’ä¸€åŒ–åˆ°0-1
        final_score = keyword_score * 0.3 + ai_score * 0.7

        return final_score

    def _determine_selection(self, keyword_result: KeywordFilterResult,
                           ai_result: Optional[AIFilterResult],
                           final_score: float) -> Tuple[bool, Optional[str]]:
        """åˆ¤æ–­æ–‡ç« æ˜¯å¦è¢«é€‰ä¸­"""
        article_title = keyword_result.article.title[:30] + "..."

        # å…³é”®è¯ç­›é€‰æœªé€šè¿‡
        if keyword_result.relevance_score < self.config.keyword_threshold:
            print(f"   âŒ {article_title}: å…³é”®è¯ç›¸å…³æ€§ä¸è¶³ ({keyword_result.relevance_score:.3f} < {self.config.keyword_threshold})")
            return False, "å…³é”®è¯ç›¸å…³æ€§ä¸è¶³"

        # ä¿®å¤ï¼šåªæœ‰é€šè¿‡AIç­›é€‰çš„æ–‡ç« æ‰èƒ½è¢«æœ€ç»ˆé€‰ä¸­
        # è¿™ç¡®ä¿äº†ç»Ÿè®¡æ•°å­—çš„ä¸€è‡´æ€§
        if ai_result is None:
            print(f"   âŒ {article_title}: æ²¡æœ‰AIç­›é€‰ç»“æœï¼Œä¸èƒ½è¢«é€‰ä¸­ (å…³é”®è¯:{keyword_result.relevance_score:.3f})")
            return False, "æ²¡æœ‰AIç­›é€‰ç»“æœ"

        # ç»¼åˆåˆ†æ•°åˆ¤æ–­
        if final_score >= self.config.final_score_threshold:
            ai_score = ai_result.evaluation.total_score if ai_result else 0
            print(f"   âœ… {article_title}: ç»¼åˆåˆ†æ•°é€šè¿‡ (æœ€ç»ˆ:{final_score:.3f}, å…³é”®è¯:{keyword_result.relevance_score:.3f}, AI:{ai_score}/30)")
            return True, None
        else:
            ai_score = ai_result.evaluation.total_score if ai_result else 0
            print(f"   âŒ {article_title}: ç»¼åˆè¯„åˆ†ä¸è¶³ (æœ€ç»ˆ:{final_score:.3f} < {self.config.final_score_threshold}, å…³é”®è¯:{keyword_result.relevance_score:.3f}, AI:{ai_score}/30)")
            return False, "ç»¼åˆè¯„åˆ†ä¸è¶³"

    def _finalize_results(self, combined_results: List[CombinedFilterResult],
                         result: FilterChainResult):
        """æ•´ç†æœ€ç»ˆç»“æœ"""
        # åˆ†ç¦»é€‰ä¸­å’Œè¢«æ‹’ç»çš„æ–‡ç« 
        selected = [r for r in combined_results if r.selected]
        rejected = [r for r in combined_results if not r.selected]

        print(f"ğŸ” _finalize_resultsè°ƒè¯•ä¿¡æ¯:")
        print(f"   combined_resultsæ€»æ•°: {len(combined_results)}")
        print(f"   selectedæ•°é‡: {len(selected)}")
        print(f"   rejectedæ•°é‡: {len(rejected)}")
        print(f"   AIç­›é€‰é€šè¿‡æ•°é‡: {result.ai_filtered_count}")

        # æ˜¾ç¤ºé€‰ä¸­æ–‡ç« çš„è¯¦ç»†ä¿¡æ¯
        for i, r in enumerate(selected):
            has_ai = "æœ‰AIç»“æœ" if r.ai_result else "æ— AIç»“æœ"
            print(f"   é€‰ä¸­æ–‡ç« {i+1}: {r.article.title[:30]}... (æœ€ç»ˆåˆ†æ•°:{r.final_score:.3f}, {has_ai})")

        # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
        if self.config.sort_by == "final_score":
            selected.sort(key=lambda x: x.final_score, reverse=True)
        elif self.config.sort_by == "relevance":
            selected.sort(key=lambda x: x.keyword_result.relevance_score if x.keyword_result else 0, reverse=True)
        elif self.config.sort_by == "timestamp":
            selected.sort(key=lambda x: x.article.published_at or datetime.min, reverse=True)

        # é™åˆ¶æœ€ç»ˆç»“æœæ•°é‡
        if len(selected) > self.config.max_final_results:
            selected = selected[:self.config.max_final_results]

        result.selected_articles = selected
        result.final_selected_count = len(selected)

        if self.config.include_rejected:
            result.rejected_articles = rejected

        # ç”Ÿæˆæ ‡ç­¾ç»Ÿè®¡
        if self.tag_analyzer:
            result.tag_statistics = self.tag_analyzer.analyze_results(selected)
            logger.info(f"æ ‡ç­¾ç»Ÿè®¡ç”Ÿæˆå®Œæˆ: {len(result.tag_statistics.tag_distribution)} ä¸ªæ ‡ç­¾")

            # æ‰“å°æ ‡ç­¾åˆ†å¸ƒæ‘˜è¦
            if result.tag_statistics.tag_distribution:
                print("ğŸ“Š æ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡:")
                for tag_name, count in sorted(result.tag_statistics.tag_distribution.items(),
                                            key=lambda x: x[1], reverse=True):
                    fill_ratio = result.tag_statistics.tag_fill_ratios.get(tag_name, 0) * 100
                    print(f"   {tag_name}: {count} ç¯‡ ({fill_ratio:.1f}%)")

                print(f"ğŸ“ˆ å¤šæ ·æ€§è¯„åˆ†: {result.tag_statistics.tag_diversity_score*100:.1f}%")
                print(f"ğŸ·ï¸  å¹³å‡æ ‡ç­¾æ•°: {result.tag_statistics.average_tags_per_article:.1f}")

                if result.tag_statistics.underrepresented_tags:
                    print(f"âš ï¸  ä»£è¡¨æ€§ä¸è¶³: {', '.join(result.tag_statistics.underrepresented_tags[:3])}")
                if result.tag_statistics.overrepresented_tags:
                    print(f"âš¡ è¿‡åº¦é›†ä¸­: {', '.join(result.tag_statistics.overrepresented_tags[:3])}")

    def _get_article_id(self, article: NewsArticle) -> str:
        """è·å–æ–‡ç« å”¯ä¸€æ ‡è¯†"""
        return article.id or f"{article.title}_{article.published_at}"

    def get_metrics(self) -> Dict[str, Any]:
        """è·å–ç­›é€‰é“¾æ€§èƒ½æŒ‡æ ‡"""
        metrics = {
            "keyword_filter": self.keyword_filter.get_metrics(),
            "ai_filter": self.ai_filter.get_metrics()
        }
        return metrics

    def reset_metrics(self):
        """é‡ç½®æ‰€æœ‰ç­›é€‰å™¨çš„æŒ‡æ ‡"""
        self.keyword_filter.reset_metrics()
        self.ai_filter.reset_metrics()
