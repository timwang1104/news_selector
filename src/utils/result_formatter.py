"""
ç­›é€‰ç»“æœæ ¼å¼åŒ–å·¥å…·
"""
import json
import csv
from datetime import datetime
from typing import List, Dict, Any, Optional
from io import StringIO

from ..filters.base import BatchFilterResult, CombinedFilterResult, SubscriptionFilterResult
from ..services.batch_filter_service import BatchFilterConfig


class ResultFormatter:
    """ç­›é€‰ç»“æœæ ¼å¼åŒ–å™¨"""
    
    @staticmethod
    def format_batch_summary(batch_result: BatchFilterResult) -> str:
        """æ ¼å¼åŒ–æ‰¹é‡ç­›é€‰æ‘˜è¦"""
        lines = []
        lines.append("=" * 60)
        lines.append("ğŸ“Š æ‰¹é‡ç­›é€‰ç»“æœæ‘˜è¦")
        lines.append("=" * 60)
        
        # åŸºæœ¬ç»Ÿè®¡
        lines.append(f"è®¢é˜…æºæ€»æ•°: {batch_result.total_subscriptions}")
        lines.append(f"æˆåŠŸå¤„ç†: {batch_result.processed_subscriptions}")
        lines.append(f"æˆåŠŸç‡: {batch_result.success_rate:.1%}")
        lines.append(f"è·å–æ–‡ç« : {batch_result.total_articles_fetched} ç¯‡")
        lines.append(f"é€‰ä¸­æ–‡ç« : {batch_result.total_articles_selected} ç¯‡")
        
        if batch_result.total_articles_fetched > 0:
            selection_rate = batch_result.total_articles_selected / batch_result.total_articles_fetched
            lines.append(f"ç­›é€‰ç‡: {selection_rate:.1%}")
        
        # æ—¶é—´ç»Ÿè®¡
        lines.append(f"æ€»è€—æ—¶: {batch_result.total_processing_time:.2f} ç§’")
        lines.append(f"è·å–è€—æ—¶: {batch_result.total_fetch_time:.2f} ç§’")
        lines.append(f"ç­›é€‰è€—æ—¶: {batch_result.total_filter_time:.2f} ç§’")
        
        # é”™è¯¯ä¿¡æ¯
        if batch_result.errors:
            lines.append(f"é”™è¯¯æ•°é‡: {len(batch_result.errors)}")
        
        if batch_result.warnings:
            lines.append(f"è­¦å‘Šæ•°é‡: {len(batch_result.warnings)}")
        
        return "\n".join(lines)
    
    @staticmethod
    def format_subscription_results(batch_result: BatchFilterResult, 
                                  show_details: bool = True) -> str:
        """æ ¼å¼åŒ–è®¢é˜…æºç»“æœ"""
        lines = []
        lines.append("\n" + "=" * 60)
        lines.append("ğŸ“° è®¢é˜…æºå¤„ç†ç»“æœ")
        lines.append("=" * 60)
        
        for i, sub_result in enumerate(batch_result.subscription_results, 1):
            lines.append(f"\n{i}. {sub_result.subscription_title}")
            lines.append(f"   è·å–: {sub_result.articles_fetched} ç¯‡")
            lines.append(f"   é€‰ä¸­: {sub_result.selected_count} ç¯‡")
            lines.append(f"   è€—æ—¶: {sub_result.total_processing_time:.2f}s")
            
            if show_details and sub_result.filter_result.selected_articles:
                lines.append("   é€‰ä¸­æ–‡ç« :")
                for j, article in enumerate(sub_result.filter_result.selected_articles[:3], 1):
                    score_info = f"(åˆ†æ•°: {article.final_score:.2f})"
                    lines.append(f"     {j}. {article.article.title[:50]}... {score_info}")
                
                if len(sub_result.filter_result.selected_articles) > 3:
                    remaining = len(sub_result.filter_result.selected_articles) - 3
                    lines.append(f"     ... è¿˜æœ‰ {remaining} ç¯‡æ–‡ç« ")
        
        return "\n".join(lines)
    
    @staticmethod
    def format_top_articles(batch_result: BatchFilterResult, 
                          top_n: int = 10,
                          group_by_subscription: bool = False) -> str:
        """æ ¼å¼åŒ–é¡¶çº§æ–‡ç« åˆ—è¡¨"""
        lines = []
        lines.append("\n" + "=" * 60)
        lines.append(f"ğŸ† ç²¾é€‰æ–‡ç«  (Top {top_n})")
        lines.append("=" * 60)
        
        all_articles = batch_result.all_selected_articles
        
        if not all_articles:
            lines.append("æš‚æ— é€‰ä¸­æ–‡ç« ")
            return "\n".join(lines)
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_articles = sorted(all_articles, key=lambda x: x.final_score, reverse=True)
        top_articles = sorted_articles[:top_n]
        
        if group_by_subscription:
            # æŒ‰è®¢é˜…æºåˆ†ç»„
            subscription_groups = {}
            for article in top_articles:
                feed_title = article.article.feed_title or "æœªçŸ¥è®¢é˜…æº"
                if feed_title not in subscription_groups:
                    subscription_groups[feed_title] = []
                subscription_groups[feed_title].append(article)
            
            for feed_title, articles in subscription_groups.items():
                lines.append(f"\nğŸ“° {feed_title}")
                lines.append("-" * 40)
                for i, article in enumerate(articles, 1):
                    lines.append(ResultFormatter._format_article_line(article, i))
        else:
            # ç»Ÿä¸€åˆ—è¡¨
            for i, article in enumerate(top_articles, 1):
                lines.append(ResultFormatter._format_article_line(article, i))
        
        return "\n".join(lines)
    
    @staticmethod
    def _format_article_line(article: CombinedFilterResult, index: int) -> str:
        """æ ¼å¼åŒ–å•ç¯‡æ–‡ç« è¡Œ"""
        title = article.article.title[:60] + "..." if len(article.article.title) > 60 else article.article.title
        score = article.final_score
        published = article.article.published.strftime("%m-%d %H:%M")
        feed = article.article.feed_title[:20] + "..." if article.article.feed_title and len(article.article.feed_title) > 20 else (article.article.feed_title or "")
        
        return f"{index:2d}. [{score:.2f}] {title} | {feed} | {published}"
    
    @staticmethod
    def export_to_json(batch_result: BatchFilterResult, 
                      include_content: bool = False) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        data = {
            "export_time": datetime.now().isoformat(),
            "summary": {
                "total_subscriptions": batch_result.total_subscriptions,
                "processed_subscriptions": batch_result.processed_subscriptions,
                "success_rate": batch_result.success_rate,
                "total_articles_fetched": batch_result.total_articles_fetched,
                "total_articles_selected": batch_result.total_articles_selected,
                "total_processing_time": batch_result.total_processing_time
            },
            "subscription_results": []
        }
        
        for sub_result in batch_result.subscription_results:
            sub_data = {
                "subscription_id": sub_result.subscription_id,
                "subscription_title": sub_result.subscription_title,
                "articles_fetched": sub_result.articles_fetched,
                "articles_selected": sub_result.selected_count,
                "processing_time": sub_result.total_processing_time,
                "selected_articles": []
            }
            
            for article in sub_result.filter_result.selected_articles:
                article_data = {
                    "id": article.article.id,
                    "title": article.article.title,
                    "url": article.article.url,
                    "published": article.article.published.isoformat(),
                    "final_score": article.final_score
                }
                
                if include_content:
                    article_data.update({
                        "summary": article.article.summary,
                        "content": article.article.content[:500] + "..." if len(article.article.content) > 500 else article.article.content
                    })
                
                if article.keyword_result:
                    article_data["keyword_score"] = article.keyword_result.relevance_score
                
                if article.ai_result:
                    article_data["ai_score"] = article.ai_result.evaluation.total_score
                    article_data["ai_reasoning"] = article.ai_result.evaluation.reasoning
                
                sub_data["selected_articles"].append(article_data)
            
            data["subscription_results"].append(sub_data)
        
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    @staticmethod
    def export_to_csv(batch_result: BatchFilterResult) -> str:
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        output = StringIO()
        writer = csv.writer(output)
        
        # å†™å…¥æ ‡é¢˜è¡Œ
        headers = [
            "è®¢é˜…æº", "æ–‡ç« æ ‡é¢˜", "URL", "å‘å¸ƒæ—¶é—´", "æœ€ç»ˆåˆ†æ•°",
            "å…³é”®è¯åˆ†æ•°", "AIåˆ†æ•°", "AIè¯„ä¼°ç†ç”±"
        ]
        writer.writerow(headers)
        
        # å†™å…¥æ•°æ®è¡Œ
        for sub_result in batch_result.subscription_results:
            for article in sub_result.filter_result.selected_articles:
                row = [
                    sub_result.subscription_title,
                    article.article.title,
                    article.article.url,
                    article.article.published.strftime("%Y-%m-%d %H:%M:%S"),
                    f"{article.final_score:.2f}",
                    f"{article.keyword_result.relevance_score:.2f}" if article.keyword_result else "",
                    f"{article.ai_result.evaluation.total_score}" if article.ai_result else "",
                    article.ai_result.evaluation.reasoning if article.ai_result else ""
                ]
                writer.writerow(row)
        
        return output.getvalue()
    
    @staticmethod
    def format_errors_and_warnings(batch_result: BatchFilterResult) -> str:
        """æ ¼å¼åŒ–é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯"""
        lines = []
        
        if batch_result.errors:
            lines.append("\n" + "=" * 60)
            lines.append("âŒ é”™è¯¯ä¿¡æ¯")
            lines.append("=" * 60)
            for i, error in enumerate(batch_result.errors, 1):
                lines.append(f"{i}. {error}")
        
        if batch_result.warnings:
            lines.append("\n" + "=" * 60)
            lines.append("âš ï¸  è­¦å‘Šä¿¡æ¯")
            lines.append("=" * 60)
            for i, warning in enumerate(batch_result.warnings, 1):
                lines.append(f"{i}. {warning}")
        
        return "\n".join(lines) if lines else ""


class ResultExporter:
    """ç»“æœå¯¼å‡ºå™¨"""
    
    @staticmethod
    def save_to_file(content: str, filename: str, encoding: str = "utf-8"):
        """ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶"""
        with open(filename, 'w', encoding=encoding) as f:
            f.write(content)
    
    @staticmethod
    def generate_filename(prefix: str, extension: str) -> str:
        """ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{prefix}_{timestamp}.{extension}"
